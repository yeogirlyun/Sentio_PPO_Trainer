{
  "training": {
    "episodes": 1000,
    "learning_rate": 0.0003,
    "batch_size": 64,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_epsilon": 0.2,
    "value_loss_coef": 0.5,
    "entropy_coef": 0.01,
    "max_grad_norm": 0.5,
    "update_epochs": 4,
    "save_interval": 50
  },
  "environment": {
    "lookback_window": 120,
    "initial_balance": 100000,
    "transaction_cost": 0.001,
    "max_position_size": 0.95,
    "reward_scaling": 1.0
  },
  "data": {
    "symbol": "QQQ",
    "timeframe": "1m",
    "data_file": "data/polygon_QQQ_1m.feather",
    "train_split": 0.8,
    "validation_split": 0.1,
    "test_split": 0.1
  },
  "model": {
    "hidden_size": 256,
    "num_layers": 3,
    "dropout": 0.1,
    "activation": "relu"
  },
  "output": {
    "model_name": "PPO Trading Model",
    "version": "1.0",
    "description": "PPO model trained on QQQ 1-minute data with technical indicators"
  }
}
